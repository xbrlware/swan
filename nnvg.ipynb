{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Net vs. Goldman\n",
    "Can an LTSM Neural Net trained on fundamentals extracted from edgar XBRL from the S&P500 pick the same long and short list as Goldman's hedgefund meta list (appologies to my high school english teacher for the run on sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Sources\n",
    "Download price and fundamental data for the S&P 500 using [pystock-crawler](https://github.com/eliangcs/pystock-crawler):  \n",
    "\n",
    "`pystock-crawler reports ../tickers.csv -o ../reports.csv ../reports.log`  \n",
    "`pystock-crawler prices ../tickers.csv -o ../prices.csv -l ../prices.log`\n",
    "\n",
    "REMIND: Use pystock-crawler symbols to get symbols for training input...\n",
    "\n",
    "X = 4 quarters of fundamental data and whether stock was up or down from the prior quarter y = whether the stock was up or down x days after the period that X was comprised of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "prices = pandas.read_csv('prices.csv', parse_dates=['date'], index_col=1)\n",
    "reports = pandas.read_csv('reports.csv', parse_dates=['date'], index_col=1)\n",
    "symbols = pandas.read_csv('symbols.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = \"MMM\"\n",
    "r = reports[reports.symbol == s].sort(ascending=True)\n",
    "p = prices[prices.symbol == s].sort(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160.07001"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.ix['2015-05-12'].close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 symbols\n"
     ]
    }
   ],
   "source": [
    "# Add closing price and delta from prior period report onto each\n",
    "X = pandas.DataFrame()\n",
    "for s in symbols['symbol'][0:4]:\n",
    "    try:\n",
    "        r = reports[reports.symbol == s].sort(ascending=True)\n",
    "        p = prices[prices.symbol == s].sort(ascending=True)\n",
    "        r['close'] = r.index.map(lambda x: p.ix[p.index[p.index.searchsorted(x)]]['close'])\n",
    "        r['delta'] = (r['close']-r['close'].shift()).fillna(0)\n",
    "        X = X.append(r)\n",
    "    except:\n",
    "        print \"Problems parsing\", s\n",
    "print \"Found\", len(X['symbol'].unique()), \"symbols\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split into train/test sets\n",
    "# Should use sklearn.cross_validation.StratifiedShuffleSplit to try and maintain industry sector % in each\n",
    "# Or bin by financial size http://www.gregreda.com/2013/10/26/using-pandas-on-the-movielens-dataset/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
